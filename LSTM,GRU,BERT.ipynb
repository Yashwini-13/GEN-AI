{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNKjd8cHGT3r+z7r4RJ8TmC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yashwini-13/GEN-AI/blob/main/LSTM%2CGRU%2CBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jZ2fGNKCVkWr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "221b4e4b-7bca-4896-cf62-4d16b0dd9198"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total words:  1783\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'and': 2,\n",
              " 'of': 3,\n",
              " 'i': 4,\n",
              " 'to': 5,\n",
              " 'a': 6,\n",
              " 'in': 7,\n",
              " 'was': 8,\n",
              " 'it': 9,\n",
              " 'as': 10,\n",
              " 'that': 11,\n",
              " 'my': 12,\n",
              " 'with': 13,\n",
              " 'he': 14,\n",
              " 'on': 15,\n",
              " 'had': 16,\n",
              " 'for': 17,\n",
              " 'which': 18,\n",
              " 'not': 19,\n",
              " 'me': 20,\n",
              " 'but': 21,\n",
              " 'were': 22,\n",
              " 'we': 23,\n",
              " 'his': 24,\n",
              " 'at': 25,\n",
              " 'they': 26,\n",
              " 'you': 27,\n",
              " 'all': 28,\n",
              " 'could': 29,\n",
              " 'there': 30,\n",
              " 'so': 31,\n",
              " 'seemed': 32,\n",
              " 'from': 33,\n",
              " 'is': 34,\n",
              " 'by': 35,\n",
              " 'them': 36,\n",
              " 'have': 37,\n",
              " 'this': 38,\n",
              " 'then': 39,\n",
              " 'driver': 40,\n",
              " 'very': 41,\n",
              " 'be': 42,\n",
              " 'through': 43,\n",
              " 'us': 44,\n",
              " 'some': 45,\n",
              " 'when': 46,\n",
              " 'or': 47,\n",
              " 'time': 48,\n",
              " 'over': 49,\n",
              " 'what': 50,\n",
              " 'horses': 51,\n",
              " 'an': 52,\n",
              " 'up': 53,\n",
              " 'said': 54,\n",
              " 'into': 55,\n",
              " 'see': 56,\n",
              " 'great': 57,\n",
              " 'out': 58,\n",
              " 'one': 59,\n",
              " 'do': 60,\n",
              " 'here': 61,\n",
              " 'know': 62,\n",
              " 'are': 63,\n",
              " 'must': 64,\n",
              " 'again': 65,\n",
              " 'though': 66,\n",
              " 'been': 67,\n",
              " 'before': 68,\n",
              " 'white': 69,\n",
              " 'down': 70,\n",
              " 'him': 71,\n",
              " 'our': 72,\n",
              " 'count': 73,\n",
              " 'door': 74,\n",
              " 'side': 75,\n",
              " 'now': 76,\n",
              " 'may': 77,\n",
              " 'no': 78,\n",
              " 'long': 79,\n",
              " 'saw': 80,\n",
              " 'old': 81,\n",
              " 'round': 82,\n",
              " 'she': 83,\n",
              " 'did': 84,\n",
              " 'began': 85,\n",
              " 'like': 86,\n",
              " 'will': 87,\n",
              " 'go': 88,\n",
              " 'would': 89,\n",
              " 'way': 90,\n",
              " 'am': 91,\n",
              " 'if': 92,\n",
              " 'looked': 93,\n",
              " 'place': 94,\n",
              " 'got': 95,\n",
              " 'came': 96,\n",
              " 'sort': 97,\n",
              " 'man': 98,\n",
              " 'her': 99,\n",
              " 'your': 100,\n",
              " 'road': 101,\n",
              " 'darkness': 102,\n",
              " 'wolves': 103,\n",
              " 'night': 104,\n",
              " 'light': 105,\n",
              " 'any': 106,\n",
              " 'than': 107,\n",
              " 'went': 108,\n",
              " 'strange': 109,\n",
              " 'come': 110,\n",
              " 'took': 111,\n",
              " 'after': 112,\n",
              " 'along': 113,\n",
              " 'country': 114,\n",
              " 'just': 115,\n",
              " 'own': 116,\n",
              " 'well': 117,\n",
              " 'who': 118,\n",
              " 'their': 119,\n",
              " 'dark': 120,\n",
              " 'back': 121,\n",
              " 'coach': 122,\n",
              " 'effect': 123,\n",
              " 'face': 124,\n",
              " 'trees': 125,\n",
              " 'same': 126,\n",
              " 'stood': 127,\n",
              " 'another': 128,\n",
              " 'dracula': 129,\n",
              " 'should': 130,\n",
              " 'far': 131,\n",
              " 'found': 132,\n",
              " 'made': 133,\n",
              " 'every': 134,\n",
              " 'howling': 135,\n",
              " 'still': 136,\n",
              " 'more': 137,\n",
              " 'day': 138,\n",
              " 'hills': 139,\n",
              " 'such': 140,\n",
              " 'each': 141,\n",
              " 'pass': 142,\n",
              " 'looking': 143,\n",
              " 'room': 144,\n",
              " 'many': 145,\n",
              " 'eyes': 146,\n",
              " 'only': 147,\n",
              " 'its': 148,\n",
              " 'swept': 149,\n",
              " 'himself': 150,\n",
              " 'hand': 151,\n",
              " 'left': 152,\n",
              " 'late': 153,\n",
              " 'little': 154,\n",
              " 'rather': 155,\n",
              " 'able': 156,\n",
              " 'carpathians': 157,\n",
              " 'without': 158,\n",
              " 'something': 159,\n",
              " 'full': 160,\n",
              " 'other': 161,\n",
              " 'heavy': 162,\n",
              " 'black': 163,\n",
              " 'once': 164,\n",
              " 'however': 165,\n",
              " 'welcome': 166,\n",
              " 'kept': 167,\n",
              " 'themselves': 168,\n",
              " 'off': 169,\n",
              " 'seat': 170,\n",
              " 'green': 171,\n",
              " 'whose': 172,\n",
              " 'flame': 173,\n",
              " 'grew': 174,\n",
              " 'calèche': 175,\n",
              " 'supper': 176,\n",
              " 'get': 177,\n",
              " 'asked': 178,\n",
              " 'bukovina': 179,\n",
              " 'yet': 180,\n",
              " 'about': 181,\n",
              " 'sleep': 182,\n",
              " 'under': 183,\n",
              " 'further': 184,\n",
              " 'kind': 185,\n",
              " 'ran': 186,\n",
              " 'evidently': 187,\n",
              " 'journey': 188,\n",
              " 'where': 189,\n",
              " 'put': 190,\n",
              " 'fear': 191,\n",
              " 'till': 192,\n",
              " 'these': 193,\n",
              " 'against': 194,\n",
              " 'passengers': 195,\n",
              " 'right': 196,\n",
              " 'upon': 197,\n",
              " 'myself': 198,\n",
              " 'bistritz': 199,\n",
              " 'morning': 200,\n",
              " 'near': 201,\n",
              " 'among': 202,\n",
              " 'good': 203,\n",
              " 'red': 204,\n",
              " 'called': 205,\n",
              " 'german': 206,\n",
              " 'london': 207,\n",
              " 'least': 208,\n",
              " 'shall': 209,\n",
              " 'going': 210,\n",
              " 'excellent': 211,\n",
              " 'sometimes': 212,\n",
              " 'wide': 213,\n",
              " 'people': 214,\n",
              " 'home': 215,\n",
              " 'coming': 216,\n",
              " 'expected': 217,\n",
              " 'too': 218,\n",
              " 'herr': 219,\n",
              " 'things': 220,\n",
              " 'two': 221,\n",
              " 'rose': 222,\n",
              " 'passed': 223,\n",
              " 'awake': 224,\n",
              " 'word': 225,\n",
              " 'amongst': 226,\n",
              " 'crossing': 227,\n",
              " 'speaking': 228,\n",
              " 'opened': 229,\n",
              " 'fell': 230,\n",
              " 'grim': 231,\n",
              " 'lamps': 232,\n",
              " 'appeared': 233,\n",
              " 'take': 234,\n",
              " 'turned': 235,\n",
              " 'heard': 236,\n",
              " 'strength': 237,\n",
              " 'felt': 238,\n",
              " 'suddenly': 239,\n",
              " 'around': 240,\n",
              " 'east': 241,\n",
              " 'done': 242,\n",
              " 'mem': 243,\n",
              " 'mina': 244,\n",
              " 'how': 245,\n",
              " 'find': 246,\n",
              " 'mountains': 247,\n",
              " 'known': 248,\n",
              " 'castle': 249,\n",
              " 'enter': 250,\n",
              " 'window': 251,\n",
              " 'towards': 252,\n",
              " 'call': 253,\n",
              " 'started': 254,\n",
              " 'carriage': 255,\n",
              " 'strong': 256,\n",
              " 'picturesque': 257,\n",
              " 'big': 258,\n",
              " 'rest': 259,\n",
              " 'hair': 260,\n",
              " 'told': 261,\n",
              " 'borgo': 262,\n",
              " 'has': 263,\n",
              " 'lost': 264,\n",
              " 'close': 265,\n",
              " 'letter': 266,\n",
              " 'friend': 267,\n",
              " 'bring': 268,\n",
              " 'land': 269,\n",
              " 'understand': 270,\n",
              " 'knew': 271,\n",
              " 'both': 272,\n",
              " 'saying': 273,\n",
              " 'state': 274,\n",
              " 'english': 275,\n",
              " 'suppose': 276,\n",
              " 'feeling': 277,\n",
              " 'sun': 278,\n",
              " 'jagged': 279,\n",
              " 'fire': 280,\n",
              " 'hear': 281,\n",
              " 'sign': 282,\n",
              " 'meant': 283,\n",
              " 'pine': 284,\n",
              " 'blue': 285,\n",
              " 'companions': 286,\n",
              " 'behind': 287,\n",
              " 'held': 288,\n",
              " 'noticed': 289,\n",
              " 'even': 290,\n",
              " 'ears': 291,\n",
              " 'gloom': 292,\n",
              " 'clouds': 293,\n",
              " 'wind': 294,\n",
              " 'smile': 295,\n",
              " 'forward': 296,\n",
              " 'teeth': 297,\n",
              " 'within': 298,\n",
              " 'sound': 299,\n",
              " 'stone': 300,\n",
              " 'jonathan': 301,\n",
              " 'next': 302,\n",
              " 'train': 303,\n",
              " 'hour': 304,\n",
              " 'seems': 305,\n",
              " 'walk': 306,\n",
              " 'station': 307,\n",
              " 'leaving': 308,\n",
              " 'most': 309,\n",
              " 'hotel': 310,\n",
              " 'paprika': 311,\n",
              " 'dish': 312,\n",
              " 'maps': 313,\n",
              " 'transylvania': 314,\n",
              " 'three': 315,\n",
              " 'four': 316,\n",
              " 'mixed': 317,\n",
              " 'read': 318,\n",
              " 'world': 319,\n",
              " 'centre': 320,\n",
              " 'stay': 321,\n",
              " 'ask': 322,\n",
              " 'queer': 323,\n",
              " 'dog': 324,\n",
              " 'water': 325,\n",
              " 'top': 326,\n",
              " 'steep': 327,\n",
              " 'lot': 328,\n",
              " 'outside': 329,\n",
              " 'peasants': 330,\n",
              " 'trousers': 331,\n",
              " 'course': 332,\n",
              " 'figures': 333,\n",
              " 'slovaks': 334,\n",
              " 'nails': 335,\n",
              " 'high': 336,\n",
              " 'set': 337,\n",
              " 'being': 338,\n",
              " 'certainly': 339,\n",
              " 'almost': 340,\n",
              " 'gave': 341,\n",
              " 'morrow': 342,\n",
              " 'trust': 343,\n",
              " 'beautiful': 344,\n",
              " 'making': 345,\n",
              " 'answered': 346,\n",
              " 'questions': 347,\n",
              " 'lady': 348,\n",
              " 'sent': 349,\n",
              " 'crossed': 350,\n",
              " 'nothing': 351,\n",
              " 'starting': 352,\n",
              " 'shook': 353,\n",
              " 'head': 354,\n",
              " 'midnight': 355,\n",
              " 'evil': 356,\n",
              " 'comfort': 357,\n",
              " 'knees': 358,\n",
              " 'crucifix': 359,\n",
              " 'neck': 360,\n",
              " 'offered': 361,\n",
              " 'meaning': 362,\n",
              " 'whilst': 363,\n",
              " 'ghostly': 364,\n",
              " 'let': 365,\n",
              " 'dined': 366,\n",
              " 'taken': 367,\n",
              " 'words': 368,\n",
              " 'crowd': 369,\n",
              " 'say': 370,\n",
              " 'either': 371,\n",
              " 'pointed': 372,\n",
              " 'fingers': 373,\n",
              " 'passenger': 374,\n",
              " 'first': 375,\n",
              " 'unknown': 376,\n",
              " 'touched': 377,\n",
              " 'last': 378,\n",
              " 'covered': 379,\n",
              " 'whip': 380,\n",
              " 'soon': 381,\n",
              " 'fears': 382,\n",
              " 'drove': 383,\n",
              " 'woods': 384,\n",
              " 'end': 385,\n",
              " 'haste': 386,\n",
              " 'general': 387,\n",
              " 'think': 388,\n",
              " 'really': 389,\n",
              " 'point': 390,\n",
              " 'mighty': 391,\n",
              " 'lofty': 392,\n",
              " 'falling': 393,\n",
              " 'shadows': 394,\n",
              " 'rock': 395,\n",
              " 'endless': 396,\n",
              " 'gleam': 397,\n",
              " 'snow': 398,\n",
              " 'mountain': 399,\n",
              " 'evening': 400,\n",
              " 'fact': 401,\n",
              " 'peculiarly': 402,\n",
              " 'carried': 403,\n",
              " 'added': 404,\n",
              " 'make': 405,\n",
              " 'excitement': 406,\n",
              " 'nearer': 407,\n",
              " 'give': 408,\n",
              " 'moment': 409,\n",
              " 'hard': 410,\n",
              " 'drew': 411,\n",
              " 'already': 412,\n",
              " 'watch': 413,\n",
              " 'tall': 414,\n",
              " 'much': 415,\n",
              " 'sharp': 416,\n",
              " 'away': 417,\n",
              " 'luggage': 418,\n",
              " 'handed': 419,\n",
              " 'reins': 420,\n",
              " 'chill': 421,\n",
              " 'ground': 422,\n",
              " 'few': 423,\n",
              " 'howl': 424,\n",
              " 'became': 425,\n",
              " 'roadway': 426,\n",
              " 'fine': 427,\n",
              " 'disappeared': 428,\n",
              " 'during': 429,\n",
              " 'moon': 430,\n",
              " 'ring': 431,\n",
              " 'jumped': 432,\n",
              " 'showed': 433,\n",
              " 'massive': 434,\n",
              " 'lamp': 435,\n",
              " 'house': 436,\n",
              " 'passage': 437,\n",
              " 'bedroom': 438,\n",
              " 'ready': 439,\n",
              " 'chapter': 440,\n",
              " \"harker's\": 441,\n",
              " 'journal': 442,\n",
              " 'early': 443,\n",
              " 'arrived': 444,\n",
              " 'glimpse': 445,\n",
              " 'feared': 446,\n",
              " 'start': 447,\n",
              " 'possible': 448,\n",
              " 'west': 449,\n",
              " 'entering': 450,\n",
              " 'splendid': 451,\n",
              " 'traditions': 452,\n",
              " 'pretty': 453,\n",
              " 'stopped': 454,\n",
              " 'dinner': 455,\n",
              " 'chicken': 456,\n",
              " 'pepper': 457,\n",
              " 'thirsty': 458,\n",
              " 'recipe': 459,\n",
              " 'anywhere': 460,\n",
              " 'indeed': 461,\n",
              " 'having': 462,\n",
              " 'struck': 463,\n",
              " 'hardly': 464,\n",
              " 'named': 465,\n",
              " 'refresh': 466,\n",
              " 'nationalities': 467,\n",
              " 'magyars': 468,\n",
              " 'latter': 469,\n",
              " 'descended': 470,\n",
              " 'huns': 471,\n",
              " 'century': 472,\n",
              " 'superstition': 473,\n",
              " 'interesting': 474,\n",
              " 'comfortable': 475,\n",
              " 'enough': 476,\n",
              " 'sorts': 477,\n",
              " 'breakfast': 478,\n",
              " 'also': 479,\n",
              " 'hurry': 480,\n",
              " 'ought': 481,\n",
              " 'move': 482,\n",
              " 'beauty': 483,\n",
              " 'edge': 484,\n",
              " 'attire': 485,\n",
              " 'hats': 486,\n",
              " 'others': 487,\n",
              " 'sleeves': 488,\n",
              " 'belts': 489,\n",
              " 'linen': 490,\n",
              " 'leather': 491,\n",
              " 'nearly': 492,\n",
              " 'foot': 493,\n",
              " 'studded': 494,\n",
              " 'look': 495,\n",
              " 'self': 496,\n",
              " 'twilight': 497,\n",
              " 'stormy': 498,\n",
              " 'years': 499,\n",
              " 'terrible': 500,\n",
              " 'war': 501,\n",
              " 'golden': 502,\n",
              " 'ways': 503,\n",
              " 'elderly': 504,\n",
              " 'woman': 505,\n",
              " 'usual': 506,\n",
              " 'peasant': 507,\n",
              " 'front': 508,\n",
              " 'coloured': 509,\n",
              " 'bowed': 510,\n",
              " 'yes': 511,\n",
              " 'harker': 512,\n",
              " 'smiled': 513,\n",
              " 'happy': 514,\n",
              " 'best': 515,\n",
              " 'true': 516,\n",
              " 'exactly': 517,\n",
              " 'wife': 518,\n",
              " 'frightened': 519,\n",
              " 'tell': 520,\n",
              " 'anything': 521,\n",
              " 'simply': 522,\n",
              " 'speak': 523,\n",
              " 'else': 524,\n",
              " 'oh': 525,\n",
              " 'young': 526,\n",
              " 'grip': 527,\n",
              " 'language': 528,\n",
              " 'business': 529,\n",
              " 'evident': 530,\n",
              " 'tried': 531,\n",
              " 'wait': 532,\n",
              " 'gravely': 533,\n",
              " 'mind': 534,\n",
              " 'part': 535,\n",
              " 'whether': 536,\n",
              " 'itself': 537,\n",
              " 'ever': 538,\n",
              " 'comes': 539,\n",
              " '5': 540,\n",
              " 'grey': 541,\n",
              " 'odd': 542,\n",
              " 'lest': 543,\n",
              " 'simple': 544,\n",
              " 'glasses': 545,\n",
              " 'talking': 546,\n",
              " 'listened': 547,\n",
              " 'repeated': 548,\n",
              " 'quietly': 549,\n",
              " 'inn': 550,\n",
              " 'considerable': 551,\n",
              " 'size': 552,\n",
              " 'cross': 553,\n",
              " 'fellow': 554,\n",
              " 'guard': 555,\n",
              " 'eye': 556,\n",
              " 'meet': 557,\n",
              " 'yard': 558,\n",
              " 'background': 559,\n",
              " 'cracked': 560,\n",
              " 'small': 561,\n",
              " 'sight': 562,\n",
              " 'lay': 563,\n",
              " 'plum': 564,\n",
              " 'grass': 565,\n",
              " 'fallen': 566,\n",
              " 'mittel': 567,\n",
              " 'losing': 568,\n",
              " 'tongues': 569,\n",
              " 'fly': 570,\n",
              " 'reaching': 571,\n",
              " 'order': 572,\n",
              " 'run': 573,\n",
              " 'always': 574,\n",
              " 'afternoon': 575,\n",
              " 'range': 576,\n",
              " 'deep': 577,\n",
              " 'peaks': 578,\n",
              " 'brown': 579,\n",
              " 'distance': 580,\n",
              " 'snowy': 581,\n",
              " 'arm': 582,\n",
              " 'wound': 583,\n",
              " 'sank': 584,\n",
              " 'lower': 585,\n",
              " 'sunset': 586,\n",
              " 'delicate': 587,\n",
              " 'cszeks': 588,\n",
              " 'turn': 589,\n",
              " 'masses': 590,\n",
              " 'silver': 591,\n",
              " 'sure': 592,\n",
              " 'seated': 593,\n",
              " 'quite': 594,\n",
              " 'carrying': 595,\n",
              " 'cold': 596,\n",
              " 'growing': 597,\n",
              " 'valleys': 598,\n",
              " 'between': 599,\n",
              " 'lying': 600,\n",
              " 'cut': 601,\n",
              " 'closing': 602,\n",
              " 'threw': 603,\n",
              " 'seem': 604,\n",
              " \"driver's\": 605,\n",
              " 'wished': 606,\n",
              " 'dogs': 607,\n",
              " 'matters': 608,\n",
              " 'wild': 609,\n",
              " 'hold': 610,\n",
              " 'several': 611,\n",
              " 'seen': 612,\n",
              " 'leaned': 613,\n",
              " 'rolling': 614,\n",
              " 'air': 615,\n",
              " 'flickering': 616,\n",
              " 'rays': 617,\n",
              " 'steam': 618,\n",
              " 'driven': 619,\n",
              " 'cloud': 620,\n",
              " 'tone': 621,\n",
              " 'thought': 622,\n",
              " 'less': 623,\n",
              " 'turning': 624,\n",
              " 'worse': 625,\n",
              " 'snort': 626,\n",
              " 'beside': 627,\n",
              " 'lamplight': 628,\n",
              " 'replied': 629,\n",
              " 'cannot': 630,\n",
              " 'spoke': 631,\n",
              " 'mouth': 632,\n",
              " 'lips': 633,\n",
              " 'whispered': 634,\n",
              " 'line': 635,\n",
              " 'dead': 636,\n",
              " 'putting': 637,\n",
              " 'bags': 638,\n",
              " 'steel': 639,\n",
              " 'prodigious': 640,\n",
              " 'across': 641,\n",
              " 'pace': 642,\n",
              " 'straight': 643,\n",
              " 'complete': 644,\n",
              " 'placed': 645,\n",
              " 'passing': 646,\n",
              " 'minutes': 647,\n",
              " 'waited': 648,\n",
              " 'fright': 649,\n",
              " 'reared': 650,\n",
              " 'stand': 651,\n",
              " 'extraordinary': 652,\n",
              " 'arched': 653,\n",
              " 'frowning': 654,\n",
              " 'rocks': 655,\n",
              " 'colder': 656,\n",
              " 'afraid': 657,\n",
              " 'faint': 658,\n",
              " 'while': 659,\n",
              " 'asleep': 660,\n",
              " 'incident': 661,\n",
              " 'nightmare': 662,\n",
              " 'deceived': 663,\n",
              " 'clad': 664,\n",
              " 'silence': 665,\n",
              " 'can': 666,\n",
              " 'living': 667,\n",
              " 'chance': 668,\n",
              " 'approach': 669,\n",
              " 'noise': 670,\n",
              " 'trap': 671,\n",
              " 'voice': 672,\n",
              " 'ascending': 673,\n",
              " 'courtyard': 674,\n",
              " 'windows': 675,\n",
              " 'remarkable': 676,\n",
              " 'led': 677,\n",
              " 'notice': 678,\n",
              " 'mine': 679,\n",
              " 'traps': 680,\n",
              " 'dim': 681,\n",
              " 'openings': 682,\n",
              " 'doubts': 683,\n",
              " \"solicitor's\": 684,\n",
              " 'clerk': 685,\n",
              " 'solicitor': 686,\n",
              " 'horrible': 687,\n",
              " 'dawn': 688,\n",
              " 'drawn': 689,\n",
              " 'moustache': 690,\n",
              " 'single': 691,\n",
              " 'chimney': 692,\n",
              " 'open': 693,\n",
              " 'motioned': 694,\n",
              " 'courtly': 695,\n",
              " 'gesture': 696,\n",
              " 'freely': 697,\n",
              " 'stepping': 698,\n",
              " 'fixed': 699,\n",
              " 'whom': 700,\n",
              " 'mr': 701,\n",
              " 'need': 702,\n",
              " 'insisted': 703,\n",
              " 'sir': 704,\n",
              " 'lit': 705,\n",
              " 'table': 706,\n",
              " 'logs': 707,\n",
              " 'closed': 708,\n",
              " 'octagonal': 709,\n",
              " 'toilet': 710,\n",
              " \"count's\": 711,\n",
              " 'courteous': 712,\n",
              " 'fireplace': 713,\n",
              " 'sup': 714,\n",
              " 'silent': 715,\n",
              " 'smoke': 716,\n",
              " 'thin': 717,\n",
              " 'nose': 718,\n",
              " 'broad': 719,\n",
              " 'hands': 720,\n",
              " 'seeing': 721,\n",
              " '3': 722,\n",
              " 'munich': 723,\n",
              " '8': 724,\n",
              " '35': 725,\n",
              " 'p': 726,\n",
              " 'm': 727,\n",
              " '1st': 728,\n",
              " 'arriving': 729,\n",
              " 'vienna': 730,\n",
              " '6': 731,\n",
              " '46': 732,\n",
              " 'buda': 733,\n",
              " 'pesth': 734,\n",
              " 'wonderful': 735,\n",
              " 'streets': 736,\n",
              " 'correct': 737,\n",
              " 'impression': 738,\n",
              " 'western': 739,\n",
              " 'bridges': 740,\n",
              " 'danube': 741,\n",
              " 'noble': 742,\n",
              " 'width': 743,\n",
              " 'depth': 744,\n",
              " 'turkish': 745,\n",
              " 'rule': 746,\n",
              " 'nightfall': 747,\n",
              " 'klausenburgh': 748,\n",
              " 'royale': 749,\n",
              " 'waiter': 750,\n",
              " 'hendl': 751,\n",
              " 'national': 752,\n",
              " 'smattering': 753,\n",
              " 'useful': 754,\n",
              " \"don't\": 755,\n",
              " 'disposal': 756,\n",
              " 'visited': 757,\n",
              " 'british': 758,\n",
              " 'museum': 759,\n",
              " 'search': 760,\n",
              " 'books': 761,\n",
              " 'library': 762,\n",
              " 'regarding': 763,\n",
              " 'foreknowledge': 764,\n",
              " 'fail': 765,\n",
              " 'importance': 766,\n",
              " 'dealing': 767,\n",
              " 'nobleman': 768,\n",
              " 'district': 769,\n",
              " 'extreme': 770,\n",
              " 'borders': 771,\n",
              " 'states': 772,\n",
              " 'moldavia': 773,\n",
              " 'midst': 774,\n",
              " 'carpathian': 775,\n",
              " 'wildest': 776,\n",
              " 'portions': 777,\n",
              " 'europe': 778,\n",
              " 'map': 779,\n",
              " 'work': 780,\n",
              " 'giving': 781,\n",
              " 'exact': 782,\n",
              " 'locality': 783,\n",
              " 'compare': 784,\n",
              " 'ordnance': 785,\n",
              " 'survey': 786,\n",
              " 'post': 787,\n",
              " 'town': 788,\n",
              " 'fairly': 789,\n",
              " 'notes': 790,\n",
              " 'memory': 791,\n",
              " 'talk': 792,\n",
              " 'travels': 793,\n",
              " 'population': 794,\n",
              " 'distinct': 795,\n",
              " 'saxons': 796,\n",
              " 'south': 797,\n",
              " 'wallachs': 798,\n",
              " 'descendants': 799,\n",
              " 'dacians': 800,\n",
              " 'szekelys': 801,\n",
              " 'north': 802,\n",
              " 'claim': 803,\n",
              " 'attila': 804,\n",
              " 'conquered': 805,\n",
              " 'eleventh': 806,\n",
              " 'settled': 807,\n",
              " 'gathered': 808,\n",
              " 'horseshoe': 809,\n",
              " 'imaginative': 810,\n",
              " 'whirlpool': 811,\n",
              " 'bed': 812,\n",
              " 'dreams': 813,\n",
              " 'drink': 814,\n",
              " 'carafe': 815,\n",
              " 'slept': 816,\n",
              " 'wakened': 817,\n",
              " 'continuous': 818,\n",
              " 'knocking': 819,\n",
              " 'guess': 820,\n",
              " 'sleeping': 821,\n",
              " 'soundly': 822,\n",
              " 'porridge': 823,\n",
              " 'maize': 824,\n",
              " 'flour': 825,\n",
              " 'mamaliga': 826,\n",
              " 'egg': 827,\n",
              " 'plant': 828,\n",
              " 'stuffed': 829,\n",
              " 'forcemeat': 830,\n",
              " 'impletata': 831,\n",
              " 'eight': 832,\n",
              " 'rushing': 833,\n",
              " '7': 834,\n",
              " '30': 835,\n",
              " 'sit': 836,\n",
              " 'unpunctual': 837,\n",
              " 'trains': 838,\n",
              " 'china': 839,\n",
              " 'dawdle': 840,\n",
              " 'towns': 841,\n",
              " 'castles': 842,\n",
              " 'missals': 843,\n",
              " 'rivers': 844,\n",
              " 'streams': 845,\n",
              " 'stony': 846,\n",
              " 'margin': 847,\n",
              " 'subject': 848,\n",
              " 'floods': 849,\n",
              " 'takes': 850,\n",
              " 'running': 851,\n",
              " 'sweep': 852,\n",
              " 'river': 853,\n",
              " 'clear': 854,\n",
              " 'groups': 855,\n",
              " 'crowds': 856,\n",
              " 'those': 857,\n",
              " 'france': 858,\n",
              " 'germany': 859,\n",
              " 'short': 860,\n",
              " 'jackets': 861,\n",
              " 'women': 862,\n",
              " 'except': 863,\n",
              " 'clumsy': 864,\n",
              " 'waist': 865,\n",
              " 'strips': 866,\n",
              " 'fluttering': 867,\n",
              " 'dresses': 868,\n",
              " 'ballet': 869,\n",
              " 'petticoats': 870,\n",
              " 'strangest': 871,\n",
              " 'barbarian': 872,\n",
              " 'cow': 873,\n",
              " 'boy': 874,\n",
              " 'baggy': 875,\n",
              " 'dirty': 876,\n",
              " 'shirts': 877,\n",
              " 'enormous': 878,\n",
              " 'brass': 879,\n",
              " 'wore': 880,\n",
              " 'boots': 881,\n",
              " 'tucked': 882,\n",
              " 'moustaches': 883,\n",
              " 'prepossessing': 884,\n",
              " 'stage': 885,\n",
              " 'oriental': 886,\n",
              " 'band': 887,\n",
              " 'brigands': 888,\n",
              " 'harmless': 889,\n",
              " 'wanting': 890,\n",
              " 'natural': 891,\n",
              " 'assertion': 892,\n",
              " 'practically': 893,\n",
              " 'frontier': 894,\n",
              " 'leads': 895,\n",
              " 'existence': 896,\n",
              " 'shows': 897,\n",
              " 'marks': 898,\n",
              " 'fifty': 899,\n",
              " 'ago': 900,\n",
              " 'series': 901,\n",
              " 'fires': 902,\n",
              " 'havoc': 903,\n",
              " 'five': 904,\n",
              " 'separate': 905,\n",
              " 'occasions': 906,\n",
              " 'beginning': 907,\n",
              " 'seventeenth': 908,\n",
              " 'underwent': 909,\n",
              " 'siege': 910,\n",
              " 'weeks': 911,\n",
              " '13': 912,\n",
              " '000': 913,\n",
              " 'casualties': 914,\n",
              " 'proper': 915,\n",
              " 'assisted': 916,\n",
              " 'famine': 917,\n",
              " 'disease': 918,\n",
              " 'directed': 919,\n",
              " 'krone': 920,\n",
              " 'delight': 921,\n",
              " 'thoroughly': 922,\n",
              " 'fashioned': 923,\n",
              " 'wanted': 924,\n",
              " 'faced': 925,\n",
              " 'cheery': 926,\n",
              " 'dress': 927,\n",
              " 'undergarment': 928,\n",
              " 'double': 929,\n",
              " 'apron': 930,\n",
              " 'stuff': 931,\n",
              " 'fitting': 932,\n",
              " 'tight': 933,\n",
              " 'modesty': 934,\n",
              " 'englishman': 935,\n",
              " 'message': 936,\n",
              " 'shirt': 937,\n",
              " 'followed': 938,\n",
              " 'immediately': 939,\n",
              " 'returned': 940,\n",
              " 'anxiously': 941,\n",
              " 'expecting': 942,\n",
              " 'diligence': 943,\n",
              " 'await': 944,\n",
              " 'enjoy': 945,\n",
              " '4': 946,\n",
              " 'landlord': 947,\n",
              " 'directing': 948,\n",
              " 'secure': 949,\n",
              " 'inquiries': 950,\n",
              " 'details': 951,\n",
              " 'somewhat': 952,\n",
              " 'reticent': 953,\n",
              " 'pretended': 954,\n",
              " 'because': 955,\n",
              " 'understood': 956,\n",
              " 'perfectly': 957,\n",
              " 'received': 958,\n",
              " 'mumbled': 959,\n",
              " 'money': 960,\n",
              " 'refused': 961,\n",
              " 'mysterious': 962,\n",
              " 'means': 963,\n",
              " 'comforting': 964,\n",
              " 'hysterical': 965,\n",
              " 'excited': 966,\n",
              " 'follow': 967,\n",
              " 'asking': 968,\n",
              " 'engaged': 969,\n",
              " 'important': 970,\n",
              " 'fourth': 971,\n",
              " 'eve': 972,\n",
              " 'st': 973,\n",
              " \"george's\": 974,\n",
              " 'clock': 975,\n",
              " 'strikes': 976,\n",
              " 'sway': 977,\n",
              " 'distress': 978,\n",
              " 'finally': 979,\n",
              " 'implored': 980,\n",
              " 'ridiculous': 981,\n",
              " 'feel': 982,\n",
              " 'allow': 983,\n",
              " 'interfere': 984,\n",
              " 'therefore': 985,\n",
              " 'raise': 986,\n",
              " 'thanked': 987,\n",
              " 'duty': 988,\n",
              " 'imperative': 989,\n",
              " 'dried': 990,\n",
              " 'taking': 991,\n",
              " 'churchman': 992,\n",
              " 'taught': 993,\n",
              " 'regard': 994,\n",
              " 'measure': 995,\n",
              " 'idolatrous': 996,\n",
              " 'ungracious': 997,\n",
              " 'refuse': 998,\n",
              " 'doubt': 999,\n",
              " 'rosary': 1000,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "with open('/content/data (3).txt','r', encoding = 'utf-8') as f:\n",
        "  text = f.read()\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "print('Total words: ', total_words)\n",
        "tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequence = []\n",
        "for line in text.split('\\n'):\n",
        "  token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "  for i in range(1, len(token_list)):\n",
        "    n_gram_sequence = token_list[:i+1]\n",
        "    input_sequence.append(n_gram_sequence)\n",
        "input_sequence[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Osze1TGsBAU",
        "outputId": "49b0c5c1-63c9-45d5-9792-5048e2c54cd5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[440, 4],\n",
              " [301, 441],\n",
              " [301, 441, 442],\n",
              " [722, 77],\n",
              " [722, 77, 199],\n",
              " [722, 77, 199, 152],\n",
              " [722, 77, 199, 152, 723],\n",
              " [722, 77, 199, 152, 723, 25],\n",
              " [722, 77, 199, 152, 723, 25, 724],\n",
              " [722, 77, 199, 152, 723, 25, 724, 725],\n",
              " [722, 77, 199, 152, 723, 25, 724, 725, 726],\n",
              " [722, 77, 199, 152, 723, 25, 724, 725, 726, 727],\n",
              " [722, 77, 199, 152, 723, 25, 724, 725, 726, 727, 15],\n",
              " [722, 77, 199, 152, 723, 25, 724, 725, 726, 727, 15, 728],\n",
              " [722, 77, 199, 152, 723, 25, 724, 725, 726, 727, 15, 728, 77],\n",
              " [722, 77, 199, 152, 723, 25, 724, 725, 726, 727, 15, 728, 77, 729],\n",
              " [722, 77, 199, 152, 723, 25, 724, 725, 726, 727, 15, 728, 77, 729, 25],\n",
              " [730, 443],\n",
              " [730, 443, 302],\n",
              " [730, 443, 302, 200]]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "extracting each line"
      ],
      "metadata": {
        "id": "elzmBkybsB67"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "take maximum length subtract the length with current list(padding)\n",
        "....."
      ],
      "metadata": {
        "id": "BZPOTOAEtywg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max([len(x) for x in input_sequence])\n",
        "print(max_len)\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "pad_sequence = pad_sequences(input_sequence, maxlen=max_len, padding='pre')\n",
        "pad_sequence[:20]\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tPmRPmSt-V1",
        "outputId": "6071a52d-e8da-44f1-9f4c-c263bb62782f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0, 440,   4],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0, 301, 441],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0, 301, 441, 442],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0, 722,  77],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0, 722,  77, 199],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        722,  77, 199, 152],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 722,\n",
              "         77, 199, 152, 723],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 722,  77,\n",
              "        199, 152, 723,  25],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 722,  77, 199,\n",
              "        152, 723,  25, 724],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 722,  77, 199, 152,\n",
              "        723,  25, 724, 725],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 722,  77, 199, 152, 723,\n",
              "         25, 724, 725, 726],\n",
              "       [  0,   0,   0,   0,   0,   0,   0, 722,  77, 199, 152, 723,  25,\n",
              "        724, 725, 726, 727],\n",
              "       [  0,   0,   0,   0,   0,   0, 722,  77, 199, 152, 723,  25, 724,\n",
              "        725, 726, 727,  15],\n",
              "       [  0,   0,   0,   0,   0, 722,  77, 199, 152, 723,  25, 724, 725,\n",
              "        726, 727,  15, 728],\n",
              "       [  0,   0,   0,   0, 722,  77, 199, 152, 723,  25, 724, 725, 726,\n",
              "        727,  15, 728,  77],\n",
              "       [  0,   0,   0, 722,  77, 199, 152, 723,  25, 724, 725, 726, 727,\n",
              "         15, 728,  77, 729],\n",
              "       [  0,   0, 722,  77, 199, 152, 723,  25, 724, 725, 726, 727,  15,\n",
              "        728,  77, 729,  25],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0, 730, 443],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0, 730, 443, 302],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        730, 443, 302, 200]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = pad_sequence[:,:-1]\n",
        "y = pad_sequence[:,-1]\n",
        "print(x.shape , y.shape)\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y, num_classes=total_words)\n",
        "print(y.shape)\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfeT9LjbvfWF",
        "outputId": "1761bc2d-5fed-44b3-ab03-bab5a669d8d3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7047, 16) (7047,)\n",
            "(7047, 1783)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "architecture development"
      ],
      "metadata": {
        "id": "ioP-ITpiwJG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM,Dense,RNN,GRU\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length=max_len-1))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.build(input_shape=(None, max_len-1))\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "b_KGuefVwLmw",
        "outputId": "159b89d2-35c9-49e4-cb68-865958ca2d21"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │       \u001b[38;5;34m178,300\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m150,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1783\u001b[0m)           │       \u001b[38;5;34m269,233\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">178,300</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1783</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">269,233</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m598,133\u001b[0m (2.28 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">598,133</span> (2.28 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m598,133\u001b[0m (2.28 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">598,133</span> (2.28 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x,y,epochs = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuBWLmKgyBX_",
        "outputId": "5266a629-f26e-4556-e367-9311e33fb7e9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.0584 - loss: 6.6590\n",
            "Epoch 2/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.0619 - loss: 5.9105\n",
            "Epoch 3/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.0822 - loss: 5.7342\n",
            "Epoch 4/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.0868 - loss: 5.5638\n",
            "Epoch 5/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.0971 - loss: 5.4348\n",
            "Epoch 6/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.1115 - loss: 5.2137\n",
            "Epoch 7/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 39ms/step - accuracy: 0.1244 - loss: 5.0188\n",
            "Epoch 8/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.1398 - loss: 4.8424\n",
            "Epoch 9/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 30ms/step - accuracy: 0.1457 - loss: 4.6702\n",
            "Epoch 10/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.1648 - loss: 4.4848\n",
            "Epoch 11/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.1784 - loss: 4.3099\n",
            "Epoch 12/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.1909 - loss: 4.1340\n",
            "Epoch 13/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.2073 - loss: 3.9751\n",
            "Epoch 14/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 29ms/step - accuracy: 0.2264 - loss: 3.7777\n",
            "Epoch 15/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 31ms/step - accuracy: 0.2438 - loss: 3.6465\n",
            "Epoch 16/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.2742 - loss: 3.4425\n",
            "Epoch 17/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 0.2920 - loss: 3.3191\n",
            "Epoch 18/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.3295 - loss: 3.1465\n",
            "Epoch 19/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.3517 - loss: 2.9967\n",
            "Epoch 20/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.3953 - loss: 2.8049\n",
            "Epoch 21/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.4284 - loss: 2.6748\n",
            "Epoch 22/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.4571 - loss: 2.5016\n",
            "Epoch 23/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 28ms/step - accuracy: 0.4942 - loss: 2.3808\n",
            "Epoch 24/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 31ms/step - accuracy: 0.5308 - loss: 2.2247\n",
            "Epoch 25/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.5550 - loss: 2.0902\n",
            "Epoch 26/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.5944 - loss: 1.9465\n",
            "Epoch 27/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.6116 - loss: 1.8649\n",
            "Epoch 28/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - accuracy: 0.6416 - loss: 1.7619\n",
            "Epoch 29/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.6700 - loss: 1.6206\n",
            "Epoch 30/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.6922 - loss: 1.5032\n",
            "Epoch 31/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.7137 - loss: 1.4261\n",
            "Epoch 32/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.7368 - loss: 1.3313\n",
            "Epoch 33/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 0.7533 - loss: 1.2598\n",
            "Epoch 34/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.7793 - loss: 1.1651\n",
            "Epoch 35/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.7807 - loss: 1.1133\n",
            "Epoch 36/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.8024 - loss: 1.0323\n",
            "Epoch 37/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 0.8315 - loss: 0.9372\n",
            "Epoch 38/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.8419 - loss: 0.8939\n",
            "Epoch 39/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.8494 - loss: 0.8297\n",
            "Epoch 40/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.8599 - loss: 0.7913\n",
            "Epoch 41/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.8699 - loss: 0.7267\n",
            "Epoch 42/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 0.8869 - loss: 0.6760\n",
            "Epoch 43/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 0.8943 - loss: 0.6381\n",
            "Epoch 44/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.9081 - loss: 0.5756\n",
            "Epoch 45/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.9192 - loss: 0.5342\n",
            "Epoch 46/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.9207 - loss: 0.5060\n",
            "Epoch 47/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 0.9335 - loss: 0.4490\n",
            "Epoch 48/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.9366 - loss: 0.4232\n",
            "Epoch 49/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.9308 - loss: 0.4156\n",
            "Epoch 50/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.9381 - loss: 0.3861\n",
            "Epoch 51/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.9404 - loss: 0.3586\n",
            "Epoch 52/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.9453 - loss: 0.3347\n",
            "Epoch 53/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.9476 - loss: 0.3132\n",
            "Epoch 54/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.9468 - loss: 0.2947\n",
            "Epoch 55/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - accuracy: 0.9554 - loss: 0.2750\n",
            "Epoch 56/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - accuracy: 0.9577 - loss: 0.2630\n",
            "Epoch 57/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.9563 - loss: 0.2389\n",
            "Epoch 58/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - accuracy: 0.9571 - loss: 0.2272\n",
            "Epoch 59/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - accuracy: 0.9602 - loss: 0.2125\n",
            "Epoch 60/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - accuracy: 0.9583 - loss: 0.2020\n",
            "Epoch 61/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.9654 - loss: 0.1841\n",
            "Epoch 62/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - accuracy: 0.9600 - loss: 0.1839\n",
            "Epoch 63/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.9617 - loss: 0.1749\n",
            "Epoch 64/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - accuracy: 0.9627 - loss: 0.1648\n",
            "Epoch 65/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - accuracy: 0.9653 - loss: 0.1534\n",
            "Epoch 66/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.9591 - loss: 0.1617\n",
            "Epoch 67/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - accuracy: 0.9640 - loss: 0.1416\n",
            "Epoch 68/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.9620 - loss: 0.1417\n",
            "Epoch 69/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.9622 - loss: 0.1352\n",
            "Epoch 70/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.9659 - loss: 0.1260\n",
            "Epoch 71/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.9632 - loss: 0.1222\n",
            "Epoch 72/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.9619 - loss: 0.1229\n",
            "Epoch 73/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - accuracy: 0.9630 - loss: 0.1166\n",
            "Epoch 74/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.9578 - loss: 0.1243\n",
            "Epoch 75/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 43ms/step - accuracy: 0.9635 - loss: 0.1075\n",
            "Epoch 76/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - accuracy: 0.9624 - loss: 0.1117\n",
            "Epoch 77/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.9652 - loss: 0.1038\n",
            "Epoch 78/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 32ms/step - accuracy: 0.9606 - loss: 0.1073\n",
            "Epoch 79/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.9642 - loss: 0.1034\n",
            "Epoch 80/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - accuracy: 0.9628 - loss: 0.1030\n",
            "Epoch 81/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.9638 - loss: 0.1013\n",
            "Epoch 82/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.9645 - loss: 0.0978\n",
            "Epoch 83/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.9613 - loss: 0.1042\n",
            "Epoch 84/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.9628 - loss: 0.0993\n",
            "Epoch 85/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.9651 - loss: 0.0953\n",
            "Epoch 86/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.9586 - loss: 0.0988\n",
            "Epoch 87/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.9619 - loss: 0.0981\n",
            "Epoch 88/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 0.9612 - loss: 0.1156\n",
            "Epoch 89/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.9676 - loss: 0.0967\n",
            "Epoch 90/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - accuracy: 0.9628 - loss: 0.0942\n",
            "Epoch 91/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step - accuracy: 0.9660 - loss: 0.0872\n",
            "Epoch 92/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.9632 - loss: 0.0885\n",
            "Epoch 93/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.9643 - loss: 0.0907\n",
            "Epoch 94/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.9620 - loss: 0.0921\n",
            "Epoch 95/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.9613 - loss: 0.0878\n",
            "Epoch 96/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.9650 - loss: 0.0873\n",
            "Epoch 97/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - accuracy: 0.9613 - loss: 0.0920\n",
            "Epoch 98/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.9634 - loss: 0.0875\n",
            "Epoch 99/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.9662 - loss: 0.0832\n",
            "Epoch 100/100\n",
            "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.9643 - loss: 0.0847\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c3e25fe2900>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('nextword.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9spxntXz5wk",
        "outputId": "ceeab03f-5a44-49d3-f491-a912e7b9080e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('nextword.h5')\n",
        "import numpy as np\n",
        "import time\n",
        "seed_text = \"I will leave if they\"\n",
        "next_words = 10\n",
        "for _ in range(next_words):\n",
        "  token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "  token_list = pad_sequences([token_list], maxlen=max_len-1, padding='pre')\n",
        "  predicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "  output_word = \"\"\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == predicted:\n",
        "      output_word = word\n",
        "  seed_text += \" \" + output_word\n",
        "print(seed_text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTNP97GV0Dh0",
        "outputId": "b9c1ce97-f929-43e1-84d6-52c54af941ab"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "I will leave if they found to my house come in the station as i\n"
          ]
        }
      ]
    }
  ]
}